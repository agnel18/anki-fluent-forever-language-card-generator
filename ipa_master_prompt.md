# ğŸŒ IPA Generation Master Prompt - 77 Languages Extension
# Version: 2026-01-07 (COMPREHENSIVE IPA COVERAGE)
# Reference: IPAService Tiered Approach (Epitran â†’ Phonemizer â†’ AI)

## ğŸ¯ MISSION
Extend IPAService to provide reliable International Phonetic Alphabet (IPA) transliterations for ALL 77 languages in our inventory using a robust tiered approach that never returns empty strings and ensures maximum quality and coverage.

## ğŸ“Š CURRENT SITUATION (January 2026)

### **âœ… What's Working**
- IPAService with basic Epitran integration
- AI fallback via Groq API
- `validate_ipa_output()` function with comprehensive IPA character support
- Support for ~14 popular languages

### **âŒ Critical Issues**
- **Limited Coverage**: Only ~14 languages supported vs. 77 needed
- **Chinese Pinyin Problem**: Epitran returns Pinyin (xÇi Ã n biÄn) instead of IPA
- **Empty Field Risk**: When validation fails, fields become blank, breaking learning experience
- **No Fallback Guarantee**: Current implementation can return empty strings
- **Missing Libraries**: No Phonemizer integration for broad coverage

### **ğŸ¯ Quality Requirements**
- **Never Empty**: Always return plausible IPA, even if validation fails
- **Maximum Quality**: Use highest-quality source available (Epitran when possible)
- **Broad Coverage**: Support all 77 languages reliably
- **Validation First**: Always run `validate_ipa_output()` but don't discard valid-looking IPA
- **Performance**: <3s average response time
- **Reliability**: <5% failure rate across all languages

## ğŸ“š COMPREHENSIVE LANGUAGE INVENTORY

### **Complete 77-Language Coverage by Family**

| Family | Languages | IPA Complexity | Current Status |
|--------|-----------|----------------|----------------|
| **1. Sino-Tibetan** (8) | Chinese Simplified âœ…, Chinese Traditional âœ…, Tibetan, Burmese, Karen, Yi, Bai, Tujia | High (tonal, logographic) | Partial |
| **2. Indo-European** (23) | English âœ…, German âœ…, Dutch âœ…, Swedish âœ…, Danish âœ…, Norwegian âœ…, Icelandic âœ…, Spanish âœ…, French âœ…, Italian âœ…, Portuguese âœ…, Romanian, Catalan, Russian âœ…, Polish, Czech, Ukrainian, Bulgarian, Serbian, Hindi âœ…, Bengali, Persian, Urdu, Punjabi, Gujarati, Marathi, Greek, Lithuanian, Latvian, Irish, Welsh, Breton, Armenian, Albanian | Medium-High (diverse scripts) | Good |
| **3. Afro-Asiatic** (12) | Arabic âœ…, Hebrew âœ…, Amharic, Hausa, Somali, Tigrinya, Berber, Coptic, Maltese | High (abugida, right-to-left) | Partial |
| **4. Niger-Congo** (15) | Swahili âœ…, Zulu, Yoruba, Igbo, Hausa, Wolof, Bambara, Ewe, Tswana, Sesotho | High (tonal, agglutinative) | Limited |
| **5. Austronesian** (7) | Malay âœ…, Indonesian, Tagalog, Maori, Hawaiian, Malagasy, Javanese | Medium (syllabic) | Partial |
| **6. Turkic** (6) | Turkish âœ…, Uzbek, Kazakh, Kyrgyz, Tatar, Azerbaijani | Medium (agglutinative) | Partial |
| **7. Dravidian** (4) | Tamil âœ…, Telugu, Kannada, Malayalam | High (retroflex, diglossia) | Partial |
| **8. Japonic** (2) | Japanese âœ…, Ryukyuan | Medium (mixed script) | Good |
| **9. Koreanic** (1) | Korean âœ… | Medium (alphabet + Sino-Korean) | Good |
| **10. Tai-Kadai** (3) | Thai âœ…, Lao, Zhuang | High (tonal, analytic) | Partial |
| **11. Hmong-Mien** (2) | Hmong, Mien | High (tonal) | Limited |
| **12. Austroasiatic** (4) | Vietnamese âœ…, Khmer, Mon, Khasi | High (monosyllabic, tonal) | Partial |
| **13. Tibeto-Burman** (6) | Tibetan âœ…, Burmese âœ…, Karen, Yi âœ…, Bai âœ…, Tujia âœ… | High (tonal, agglutinative) | Partial |
| **14. Nubian** (1) | Nobiin | High (endangered, tonal) | None |
| **15. Basque** (1) | Basque âœ… | Medium (isolate) | Good |
| **16. Na-Dene** (2) | Navajo, Apache | High (complex consonants) | Limited |
| **17. Eskimo-Aleut** (2) | Inuit, Aleut | High (polysynthetic) | Limited |
| **18. Australian Aboriginal** (3) | Pitjantjatjara, Warlpiri, Arrernte | High (complex phonology) | None |

**PROGRESS TRACKING:**
- âœ… **FULLY SUPPORTED**: 14 languages (English, Spanish, Hindi, Arabic, etc.)
- ğŸ”„ **PARTIALLY SUPPORTED**: 40+ languages via Epitran
- â³ **NEEDS IMPLEMENTATION**: 23 languages (Niger-Congo, Hmong-Mien, etc.)
- ğŸ¯ **TARGET**: 100% coverage with acceptable quality

## ğŸ—ï¸ TECHNICAL APPROACH: TIERED IPA GENERATION

### **Three-Tier Architecture**

#### **Tier 1: Epitran (Highest Quality, Selective)**
```python
# Highest quality IPA when available
# Supports ~60/77 languages
# Linguistic rule-based transliteration
epi = epitran.Epitran("hin-Deva")  # Hindi in Devanagari
ipa = epi.transliterate("à¤¨à¤®à¤¸à¥à¤¤à¥‡")  # â†’ [nÉ™mÉ™ste]
```

#### **Tier 2: Phonemizer + espeak-ng (Broad Coverage, Good Quality)**
```python
# Supports 100+ languages via speech synthesis
# Good quality for most languages
import phonemizer
ipa = phonemizer.phonemize("hello", language="en", backend="espeak")
# â†’ "hÉ™ËˆlÉ™ÊŠ"
```

#### **Tier 3: AI-Generated IPA (Universal Fallback)**
```python
# Always available, variable quality
# Never returns empty (guaranteed fallback)
ai_ipa = get_ai_ipa(text, language)  # From Groq API
```

### **Critical Design Principles**

#### **1. Never Return Empty**
```python
def generate_ipa_hybrid(self, text: str, language: str, ai_ipa: str = "") -> str:
    """GUARANTEED: Never returns empty string."""
    # Try all tiers, return best available
    # Final fallback: meaningful placeholder
    return ipa or ai_ipa or f"[IPA unavailable for {language}]"
```

#### **2. Validation But Not Rejection**
```python
def _validate_ipa(self, ipa: str, language: str) -> bool:
    """Validate but allow best-effort returns."""
    is_valid, msg = validate_ipa_output(ipa, language)
    if is_valid:
        return True
    # Log warning but don't discard - return best effort
    logger.warning(f"IPA validation failed: {msg}")
    return len(ipa.strip()) > 0  # Accept if not empty
```

#### **3. Chinese Special Handling**
```python
# Skip Epitran for Chinese (returns Pinyin)
if language in ["Chinese (Simplified)", "Chinese (Traditional)"]:
    epitran_result = ""  # Skip to Phonemizer
```

## ğŸ“‹ IMPLEMENTATION PHASES

### **Phase 1: Research & Architecture (Week 1)**

#### **1.1 Complete Language Mappings**
**Epitran Codes** (60/77 supported):
```python
self.epitran_map = {
    "English": "eng-Latn",
    "Hindi": "hin-Deva",
    "Arabic": "ara-Arab",
    "Chinese (Simplified)": None,  # Skip
    "Chinese (Traditional)": None,  # Skip
    # ... complete mappings for all 77
}
```

**Phonemizer Codes** (77/77 supported):
```python
self.phonemizer_map = {
    "English": "en",
    "Hindi": "hi",
    "Arabic": "ar",
    "Chinese (Simplified)": "cmn",  # Mandarin
    "Chinese (Traditional)": "cmn",  # Mandarin
    # ... complete mappings for all 77
}
```

#### **1.2 Dependency Setup**
```bash
# Install phonemizer
pip install phonemizer

# Install espeak-ng (Windows via conda)
conda install -c conda-forge espeak-ng
```

#### **1.3 Architecture Validation**
- Test phonemizer installation on target platforms
- Validate espeak-ng backend availability
- Confirm compatibility with existing codebase

### **Phase 2: Core Implementation (Week 2)**

#### **2.1 IPAService Class Extension**
```python
class IPAService:
    def __init__(self):
        # Existing mappings
        self.language_map = {...}
        
        # New comprehensive mappings
        self.epitran_map = self._load_epitran_mappings()
        self.phonemizer_map = self._load_phonemizer_mappings()
    
    def generate_ipa_hybrid(self, text: str, language: str, ai_ipa: str = "") -> str:
        """Three-tier IPA generation with guaranteed non-empty return."""
        
        # Tier 1: Epitran (highest quality)
        ipa = self._try_epitran(text, language)
        if ipa and self._validate_ipa(ipa, language):
            return ipa
        
        # Tier 2: Phonemizer (broad coverage)
        ipa = self._try_phonemizer(text, language)
        if ipa and self._validate_ipa(ipa, language):
            return ipa
        
        # Tier 3: AI fallback (guaranteed)
        return self._ensure_fallback_ipa(ai_ipa, text, language)
```

#### **2.2 Epitran Implementation**
```python
def _try_epitran(self, text: str, language: str) -> str:
    """Attempt Epitran transliteration."""
    # Skip Chinese (returns Pinyin)
    if "Chinese" in language:
        return ""
    
    epi_code = self.epitran_map.get(language)
    if not epi_code:
        return ""
    
    try:
        import epitran
        epi = epitran.Epitran(epi_code)
        ipa = epi.transliterate(text)
        
        # Validate basic quality
        if ipa and ipa != text and len(ipa.strip()) > 0:
            return ipa
        return ""
        
    except Exception as e:
        logger.warning(f"Epitran failed for {language}: {e}")
        return ""
```

#### **2.3 Phonemizer Implementation**
```python
def _try_phonemizer(self, text: str, language: str) -> str:
    """Attempt Phonemizer with espeak-ng backend."""
    phone_code = self.phonemizer_map.get(language)
    if not phone_code:
        return ""
    
    try:
        import phonemizer
        
        # Configure for IPA output
        ipa = phonemizer.phonemize(
            text,
            language=phone_code,
            backend='espeak',
            strip=True,
            preserve_punctuation=False,
            with_stress=True  # Include stress marks
        )
        
        # Clean and validate
        ipa = ipa.strip()
        if ipa and len(ipa) > 0:
            return ipa
        return ""
        
    except Exception as e:
        logger.warning(f"Phonemizer failed for {language}: {e}")
        return ""
```

#### **2.4 Validation & Fallback Logic**
```python
def _validate_ipa(self, ipa: str, language: str) -> bool:
    """Validate IPA but allow best-effort returns."""
    if not ipa or not ipa.strip():
        return False
    
    # Use existing validation function
    from generation_utils import validate_ipa_output
    is_valid, validation_msg = validate_ipa_output(ipa, language)
    
    if is_valid:
        return True
    
    # Log but don't reject - accept best effort
    logger.warning(f"IPA validation failed for {language}: {validation_msg}")
    
    # Basic quality checks
    ipa_clean = ipa.strip()
    
    # Reject obvious Pinyin (Chinese tone marks)
    if any(char in ipa_clean for char in 'ÄÄ“Ä«ÅÅ«Ç–ÇÄ›ÇÇ’Ç”Çš'):
        logger.warning(f"Rejected Pinyin in IPA for {language}")
        return False
    
    # Accept if it has IPA-like content
    return len(ipa_clean) > 0

def _ensure_fallback_ipa(self, ai_ipa: str, text: str, language: str) -> str:
    """Guarantee non-empty IPA return."""
    # Try AI IPA first
    if ai_ipa and ai_ipa.strip():
        # Validate but accept even if validation fails
        if self._validate_ipa(ai_ipa, language):
            return ai_ipa
        # Still return if it looks plausible
        if len(ai_ipa.strip()) > 0:
            return ai_ipa
    
    # Ultimate fallback: meaningful placeholder
    logger.warning(f"All IPA tiers failed for {language}, using placeholder")
    return f"[IPA unavailable for {language}]"
```

### **Phase 3: Testing & Quality Assurance (Week 3)**

#### **3.1 Comprehensive Testing Strategy**

##### **3.1.1 Complete Language Coverage Testing**
```python
# Test all 77 languages with native script examples
COMPREHENSIVE_TEST_CASES = [
    # Indo-European (23 languages)
    ("English", "hello world", "hÉ™ËˆlÉ™ÊŠ wÉœËld"),
    ("Spanish", "hola mundo", "Ëˆola Ëˆmundo"),
    ("French", "bonjour le monde", "bÉ”ÌƒÊ’uÊ lÉ™ mÉ”Ìƒd"),
    ("German", "hallo welt", "Ëˆhalo ËˆvÉ›lt"),
    ("Italian", "ciao mondo", "ËˆtÊƒao Ëˆmondo"),
    ("Portuguese", "olÃ¡ mundo", "oËˆla ËˆmÅ©du"),
    ("Russian", "Ğ¿Ñ€Ğ¸Ğ²ĞµÑ‚ Ğ¼Ğ¸Ñ€", "ËˆprÊ²ivÊ²Éªt mÊ²ir"),
    ("Hindi", "à¤¨à¤®à¤¸à¥à¤¤à¥‡ à¤¦à¥à¤¨à¤¿à¤¯à¤¾", "nÉ™mÉ™ste dunijÉ‘"),
    ("Arabic", "Ù…Ø±Ø­Ø¨Ø§ Ø¨Ø§Ù„Ø¹Ø§Ù„Ù…", "marÄ§aban bÉªlÊ•É‘lÃ¦m"),
    ("Persian", "Ø³Ù„Ø§Ù… Ø¯Ù†ÛŒØ§", "sÃ¦lÉ‘m donjÉ‘"),
    ("Urdu", "ÛÛŒÙ„Ùˆ Ø¯Ù†ÛŒØ§", "heËloË dunjÉ‘Ë"),
    ("Bengali", "à¦“à¦¹à§‡ à¦¬à¦¿à¦¶à§à¦¬", "ohÄ“ biÅ›ba"),
    ("Punjabi", "à¨¸à¨¤à¨¿ à¨¸à©à¨°à©€ à¨…à¨•à¨¾à¨² à¨¦à©à¨¨à¨¿à¨†", "sÉ™t srÄ« É™kÉ‘l dunÉªÉ‘"),
    ("Gujarati", "àª¹à«‡àª²à«‹ àªµàª¿àª¶à«àªµ", "hÉ›lo viÊƒva"),
    ("Marathi", "à¤¹à¥…à¤²à¥‹ à¤µà¤¿à¤¶à¥à¤µ", "hÉ›lo viÊƒva"),
    ("Greek", "Î³ÎµÎ¹Î± ÏƒÎ¿Ï… ÎºÏŒÏƒÎ¼Îµ", "Êa su Ëˆkozme"),
    ("Polish", "czeÅ›Ä‡ Å›wiecie", "ËˆtÊ‚É›É•É• É•fÊ²atÉ•É›"),
    ("Czech", "ahoj svÄ›te", "ËˆaÉ¦oj ËˆsvjÉ›tÉ›"),
    ("Ukrainian", "Ğ¿Ñ€Ğ¸Ğ²Ñ–Ñ‚ ÑĞ²Ñ–Ñ‚Ğµ", "prÉªËˆvÊ²it ËˆsÊ²vÊ²ite"),
    ("Bulgarian", "Ğ·Ğ´Ñ€Ğ°Ğ²ĞµĞ¹ ÑĞ²ÑÑ‚", "zdraËˆvÉ›j svÊ²at"),
    ("Serbian", "Ğ·Ğ´Ñ€Ğ°Ğ²Ğ¾ ÑĞ²ĞµÑ‚Ğµ", "zdrÉ‘ËvÉ” svÉ›tÉ›"),
    ("Dutch", "hallo wereld", "ËˆÉ¦É‘loË ËˆÊ‹eËrÉ™lt"),
    ("Swedish", "hej vÃ¤rlden", "ËˆhÉ›jË ËˆÊ‹Ã¦ËÉ–É›n"),
    ("Danish", "hej verden", "Ëˆhaj ËˆveËÉÌ¯n"),
    ("Norwegian", "hei verden", "hÃ¦Éª ËˆÊ‹Ã¦ËÉ³"),
    ("Icelandic", "hallÃ³ heimur", "Ëˆhatlou ËˆhÉ›imÊr"),
    ("Romanian", "salut lume", "saËˆlut Ëˆlume"),
    ("Catalan", "hola mÃ³n", "ËˆÉ”lÉ™ Ëˆmon"),
    ("Lithuanian", "labas pasauli", "ËˆlÉbÉs pÉsÉËˆÊŠlÊ²i"),
    ("Latvian", "sveiki pasaule", "ËˆsÊ‹eiki ËˆpasÉ‘ule"),
    ("Irish", "dia duit domhan", "ËˆdÊ²iÉ™ ËˆdÌªË ÉªtÌªË  ËˆdÌªË oËn"),
    ("Welsh", "helo byd", "ËˆhÉ›lÉ” ËˆbÉªd"),
    ("Breton", "demat bed", "ËˆdÉ›mÉ‘d ËˆbeËd"),
    ("Armenian", "Õ¢Õ¡Ö€Ö‡ Õ¡Õ·Õ­Õ¡Ö€Õ°", "paÉ¹É›v aÊƒÏ‡aÉ¹h"),
    ("Albanian", "pÃ«rshÃ«ndetje botÃ«", "pÉ™rÊƒÉ™ndÉ›tjÉ› bÉ”tÉ™"),
    
    # Sino-Tibetan (8 languages)
    ("Chinese (Simplified)", "ä½ å¥½ä¸–ç•Œ", "niË§Ë¥ xÉ‘ÊŠË§Ë© Ê‚iË¥Ë© tÉ•iÉ›Ë¥Ë©"),  # Phonemizer
    ("Chinese (Traditional)", "ä½ å¥½ä¸–ç•Œ", "niË§Ë¥ xÉ‘ÊŠË§Ë© Ê‚iË¥Ë© tÉ•iÉ›Ë¥Ë©"),  # Phonemizer
    ("Tibetan", "à½–à½€à¾²à¼‹à½¤à½²à½¦à¼‹à½–à½‘à½ºà¼‹à½£à½ºà½‚à½¦", "tÊ°akÊ‚i teËlÉ›k"),  # Epitran
    ("Burmese", "á€™á€„á€ºá€¹á€‚á€œá€¬á€•á€« á€€á€™á€¹á€˜á€¬á€œá€±á€¬á€€", "mÉªÌ€É´É¡É™lÃ pÃ  kÉ™mbÃ  lÃ²ÊŠÊ”"),  # Epitran
    ("Yi", "ê†ˆêŒ ê±ê‚·", "noÊ‚i"),  # Epitran
    ("Bai", "ä½ å¥½ä¸–ç•Œ", "noÊ‚i"),  # Fallback
    ("Karen", "á€™á€‚á¤á€œá€¬á€•á€« á€€á€™á€¹á€˜á€¬á€œá€±á€¬á€€", "mÉ™É¡É™lÉ‘ pÉ‘ kÉ™mbÉ‘ lÉ‘ÊŠÊ”"),  # Fallback
    ("Tujia", "ä½ å¥½ä¸–ç•Œ", "noÊ‚i"),  # Fallback
    
    # Afro-Asiatic (12 languages)
    ("Hebrew", "×©×œ×•× ×¢×•×œ×", "ÊƒaËˆlom Ê•oËˆlam"),
    ("Amharic", "áˆ°áˆ‹áˆ áŠ áˆˆáˆ", "sÉ™lam alÉ™m"),
    ("Hausa", "sannu duniya", "sannu duniËaË"),
    ("Somali", "salam adduunka", "salaam adduunka"),
    ("Tigrinya", "áˆ°áˆ‹áˆ›á‰µ á‹“áˆˆáˆ", "sÉ™lamat Ê•alÉ™m"),
    ("Berber", "azul adunit", "azul adunit"),  # Fallback
    ("Coptic", "â²¬â²â²“â²£â²‰ â²•â²Ÿâ²¥â²™â²Ÿâ²¥", "kÊ°É›ËÉ¾e kosmos"),  # Epitran
    ("Maltese", "Ä§ello dinja", "ÉªlËu dinja"),
    
    # Niger-Congo (15 languages)
    ("Swahili", "habari dunia", "hÉ‘ËˆbÉ‘ri dunÉªËˆÉ‘"),
    ("Zulu", "sawubona mhlaba", "sÉ‘ËËˆbuËnÉ‘ mÌ©É¬É‘ËbÉ‘"),
    ("Yoruba", "mo ki ile aye", "mÅ kÄ« ilÄ“ ayÄ“"),
    ("Igbo", "kedu á»¥wa", "kÉ›du ÊŠwa"),
    ("Hausa", "sannu duniya", "sannu duniËaË"),  # Duplicate
    ("Wolof", "salam Ã dduna", "salaam Ã dduna"),
    ("Bambara", "i ni ce dunuya", "i ni tÊƒÉ› dunuya"),
    ("Ewe", "woe xexeame", "woe xexeame"),
    ("Tswana", "dumela lefatshe", "dumÉ›lÉ‘ lÉ›fÉ‘tsÊ°É›"),
    ("Sesotho", "lumela lefatshe", "lumÉ›lÉ‘ lÉ›fÉ‘tsÊ°É›"),
    
    # Austronesian (7 languages)
    ("Malay", "hello dunia", "hÉ›lo dunia"),
    ("Indonesian", "halo dunia", "halo dunia"),
    ("Tagalog", "kamusta mundo", "kamusta mundo"),
    ("Maori", "kia ora ao", "kia ËˆoÉ¾a ao"),
    ("Hawaiian", "aloha honua", "É™ËˆloÊŠhÉ™ hoËˆnuÉ™"),
    ("Malagasy", "salama tontolo izao", "salama tontolo izao"),
    ("Javanese", "halo jagad", "halo dÊ’É‘É¡É‘d"),
    
    # Turkic (6 languages)
    ("Turkish", "merhaba dÃ¼nya", "mÉ›É¾ËˆhÉ‘bÉ‘ ËˆdunjÉ‘"),
    ("Uzbek", "salom dunyo", "sÃ¦lÉ”m dunjÉ”"),
    ("Kazakh", "ÑÓ™Ğ»ĞµĞ¼ Ó™Ğ»ĞµĞ¼", "sÃ¦lÉ›m Ã¦lÉ›m"),
    ("Kyrgyz", "ÑĞ°Ğ»Ğ°Ğ¼ Ğ´Ò¯Ğ¹Ğ½Ó©", "salaËm dyjnÃ¸"),
    ("Tatar", "ÑÓ™Ğ»Ğ°Ğ¼ Ğ´Ó©Ğ½ÑŒÑ", "sÉ™lÉ‘m dÓ©njÉ‘"),
    ("Azerbaijani", "salam dÃ¼nya", "sÉ‘lÉ‘m dunjÉ‘"),
    
    # Dravidian (4 languages)
    ("Tamil", "à®…à®©à¯ˆà®¤à¯à®¤à¯à®®à¯ à®šà®°à®¿à®¯à®¾à®• à®‡à®°à¯à®•à¯à®•à®¿à®±à®¤à¯", "É™nÉ›ttum sÉ™riyÉ‘ËkÉ™ irukkirÉ™tu"),
    ("Telugu", "à°¹à°²à±‹ à°ªà±à°°à°ªà°‚à°šà°‚", "É¦É™loË prÉ™pÉ™É²tÊƒÉ™m"),
    ("Kannada", "à²¹à³à²¯à²¾à²²à³‹ à²²à³‹à²•", "hjÉ‘ËloË loËkÉ™"),
    ("Malayalam", "à´¹à´²àµ‹ à´²àµ‹à´•à´‚", "É¦É™loË loËkÉ™m"),
    
    # Japonic (2 languages)
    ("Japanese", "ã“ã‚“ã«ã¡ã¯ä¸–ç•Œ", "konËˆnitÊƒiwa seËˆkai"),
    ("Ryukyuan", "ã“ã‚“ã«ã¡ã¯ä¸–ç•Œ", "konËˆnitÊƒiwa seËˆkai"),  # Fallback to Japanese
    
    # Koreanic (1 language)
    ("Korean", "ì•ˆë…•í•˜ì„¸ìš” ì„¸ê³„", "anÉ²ÊŒÅ‹hasÉ›jo sÉ›kÊ²e"),
    
    # Tai-Kadai (3 languages)
    ("Thai", "à¸ªà¸§à¸±à¸ªà¸”à¸µà¹‚à¸¥à¸", "sÃ -wÃ t-dii lÃ´ok"),
    ("Lao", "àºªàº°àºšàº²àºàº”àºµà»‚àº¥àº", "sÉ™pÉ‘Ëj diË loËk"),
    ("Zhuang", "ä½ å¥½ä¸–ç•Œ", "mbwn"),  # Fallback
    
    # Hmong-Mien (2 languages)
    ("Hmong", "nyob zoo ntiaj teb", "nyob zoo ntiaj teb"),
    ("Mien", "nyob zoo ntiaj teb", "nyob zoo ntiaj teb"),  # Fallback
    
    # Austroasiatic (4 languages)
    ("Vietnamese", "xin chÃ o tháº¿ giá»›i", "sin tÊƒaËÊŠÌ¯ tÊ°eÌ‚Ë€ Ê’É”Ì‚Ë€i"),
    ("Khmer", "á‡áŸ†ášá¶á”áŸá½áš á–á·á—á–á›áŸ„á€", "cumriÉ™p suÉ™ pÊ°iÊ”pÊ°É™p lok"),
    ("Mon", "á€Ÿá€šá€ºá€œá€­á€¯ á€€á€™á€¹á€˜á€¬", "hÉ™lÉ” kÉ™mbÉ‘"),
    ("Khasi", "khublei shibun ki", "khublei Êƒibun ki"),
    
    # Other isolates and small families
    ("Basque", "kaixo mundua", "kajÊƒo mundua"),
    ("Navajo", "yÃ¡'Ã¡t'Ã©Ã©h nÃ­Å‚ch'i", "jÉ‘Ê”É‘tÊ”eËh nÉªÉ¬tÊƒÊ”i"),
    ("Apache", "da'anzho nahaÅ‚'aah", "dÉ‘Ê”É‘nzÊ°o nÉ‘hÉ‘É¬Ê”É‘Ëh"),  # Fallback
    ("Inuit", "ai", "ai"),
    ("Aleut", "alakay", "alakay"),
    ("Pitjantjatjara", "palya", "palya"),
    ("Warlpiri", "warrkirdi", "warrkirdi"),
    ("Arrernte", "altyerre", "altyerre"),
    ("Nubian", "asalam", "asalam"),
]

def test_all_77_languages_coverage():
    """Test that all 77 languages return non-empty IPA."""
    ipa_service = IPAService()
    
    for language, text, expected_pattern in COMPREHENSIVE_TEST_CASES:
        ipa = ipa_service.generate_ipa_hybrid(text, language)
        
        # Never empty assertion
        assert ipa, f"Empty IPA for {language} with text: {text}"
        
        # No Pinyin contamination
        assert not any(char in ipa for char in 'ÄÄ“Ä«ÅÅ«Ç–ÇÄ›ÇÇ’Ç”Çš'), f"Pinyin detected in {language} IPA: {ipa}"
        
        # Basic quality checks
        assert len(ipa.strip()) > 0, f"IPA is only whitespace for {language}"
        assert ipa != text, f"IPA identical to input text for {language}: {text}"
        
        print(f"âœ… {language}: {text} â†’ {ipa}")
```

##### **3.1.2 Edge Case Testing**
```python
def test_edge_cases():
    """Test edge cases and error conditions."""
    ipa_service = IPAService()
    
    # Empty input
    assert ipa_service.generate_ipa_hybrid("", "English") == ""
    
    # Whitespace only
    assert ipa_service.generate_ipa_hybrid("   ", "English") == ""
    
    # Unsupported language (should use AI fallback)
    ipa = ipa_service.generate_ipa_hybrid("test", "Unsupported Language", "fallback_ipa")
    assert ipa == "fallback_ipa"
    
    # Very long text
    long_text = "hello world " * 100
    ipa = ipa_service.generate_ipa_hybrid(long_text, "English")
    assert ipa and len(ipa) > 0
    
    # Special characters and punctuation
    special_text = "hello, world! ä½ å¥½ã€‚"
    ipa = ipa_service.generate_ipa_hybrid(special_text, "English")
    assert ipa and len(ipa) > 0
    
    # Numbers and symbols
    numeric_text = "123 hello 456"
    ipa = ipa_service.generate_ipa_hybrid(numeric_text, "English")
    assert ipa and len(ipa) > 0
```

##### **3.1.3 Tier Fallback Testing**
```python
def test_tier_fallback_behavior():
    """Test that tiers fall back correctly when higher tiers fail."""
    ipa_service = IPAService()
    
    # Test Chinese skips Epitran (uses Phonemizer)
    ipa = ipa_service.generate_ipa_hybrid("ä½ å¥½", "Chinese (Simplified)")
    assert ipa  # Should get Phonemizer result
    assert not any(char in ipa for char in 'ÄÄ“Ä«ÅÅ«Ç–'), "Chinese should not return Pinyin"
    
    # Test language with no Epitran support (uses Phonemizer)
    ipa = ipa_service.generate_ipa_hybrid("hello", "Hmong")
    assert ipa  # Should get Phonemizer result
    
    # Test complete failure scenario (uses AI fallback)
    ipa = ipa_service.generate_ipa_hybrid("test", "English", "ai_fallback_ipa")
    # Should prefer Epitran over AI fallback
    assert ipa != "ai_fallback_ipa"  # Epitran should work
    
    # Test with invalid AI fallback (uses placeholder)
    ipa = ipa_service.generate_ipa_hybrid("test", "Unsupported", "")
    assert ipa == "[IPA unavailable for Unsupported]"
```

##### **3.1.4 Validation Best-Effort Testing**
```python
def test_validation_best_effort():
    """Test that validation allows best-effort returns."""
    ipa_service = IPAService()
    
    # Mock a scenario where validation fails but we still return result
    # This tests the _validate_ipa method's best-effort logic
    
    # Test with AI IPA that might not pass validation
    ai_ipa = "invalid_but_present"
    ipa = ipa_service.generate_ipa_hybrid("test", "English", ai_ipa)
    assert ipa  # Should not be empty even if validation fails
    
    # Test with plausible but non-valid IPA
    ai_ipa = "tÉ›st wÉœrd"  # Looks IPA-like but may not pass strict validation
    ipa = ipa_service.generate_ipa_hybrid("test", "English", ai_ipa)
    assert ipa  # Should accept best-effort
```

#### **3.2 Quality Assessment Framework**

##### **3.2.1 Automated Quality Metrics**
```python
def assess_ipa_quality_comprehensive(ipa_results: Dict[str, str], test_cases: List[Tuple[str, str, str]]) -> Dict[str, Any]:
    """Comprehensive quality assessment for all languages."""
    metrics = {
        "coverage": {"total": len(test_cases), "successful": 0, "failed": 0},
        "quality": {"validation_pass": 0, "validation_fail": 0, "pinyin_free": 0},
        "performance": {"avg_response_time": 0.0, "max_response_time": 0.0},
        "content": {"avg_length_ratio": 0.0, "empty_returns": 0},
        "by_family": {},
        "by_tier": {"epitran": 0, "phonemizer": 0, "ai_fallback": 0, "placeholder": 0}
    }
    
    response_times = []
    
    for (language, text, expected), ipa in zip(test_cases, ipa_results.values()):
        start_time = time.time()
        
        # Coverage metrics
        if ipa and ipa.strip():
            metrics["coverage"]["successful"] += 1
        else:
            metrics["coverage"]["failed"] += 1
            metrics["content"]["empty_returns"] += 1
        
        # Quality metrics
        is_valid, msg = validate_ipa_output(ipa, language)
        if is_valid:
            metrics["quality"]["validation_pass"] += 1
        else:
            metrics["quality"]["validation_fail"] += 1
        
        # Pinyin contamination check
        has_pinyin = any(char in ipa for char in 'ÄÄ“Ä«ÅÅ«Ç–ÇÄ›ÇÇ’Ç”Çš')
        if not has_pinyin:
            metrics["quality"]["pinyin_free"] += 1
        
        # Content analysis
        if text and ipa:
            length_ratio = len(ipa) / len(text)
            metrics["content"]["avg_length_ratio"] += length_ratio
        
        # Family categorization
        family = get_language_family(language)
        if family not in metrics["by_family"]:
            metrics["by_family"][family] = {"count": 0, "quality_score": 0.0}
        metrics["by_family"][family]["count"] += 1
        metrics["by_family"][family]["quality_score"] += 1.0 if is_valid else 0.0
        
        # Tier identification (would need to be tracked during generation)
        # metrics["by_tier"][detect_used_tier(ipa, language)] += 1
        
        response_time = time.time() - start_time
        response_times.append(response_time)
    
    # Calculate averages
    if response_times:
        metrics["performance"]["avg_response_time"] = sum(response_times) / len(response_times)
        metrics["performance"]["max_response_time"] = max(response_times)
    
    if metrics["content"]["avg_length_ratio"] > 0:
        metrics["content"]["avg_length_ratio"] /= metrics["coverage"]["total"]
    
    # Calculate family averages
    for family in metrics["by_family"]:
        count = metrics["by_family"][family]["count"]
        if count > 0:
            metrics["by_family"][family]["quality_score"] /= count
    
    return metrics

def get_language_family(language: str) -> str:
    """Map language to its language family."""
    family_map = {
        # Indo-European
        "English": "Indo-European", "Spanish": "Indo-European", "French": "Indo-European",
        "German": "Indo-European", "Italian": "Indo-European", "Portuguese": "Indo-European",
        "Russian": "Indo-European", "Hindi": "Indo-European", "Arabic": "Afro-Asiatic",
        # ... complete mapping for all languages
    }
    return family_map.get(language, "Other")
```

##### **3.2.2 Manual Quality Review Process**
```python
def manual_quality_review_sample():
    """Generate sample for manual quality review."""
    ipa_service = IPAService()
    
    # Sample 20 languages for manual review
    review_languages = [
        "English", "Spanish", "French", "German", "Chinese (Simplified)",
        "Japanese", "Korean", "Hindi", "Arabic", "Russian",
        "Portuguese", "Italian", "Dutch", "Swedish", "Greek",
        "Hebrew", "Tamil", "Thai", "Vietnamese", "Swahili"
    ]
    
    review_results = {}
    
    for language in review_languages:
        test_text = get_sample_text_for_language(language)
        ipa = ipa_service.generate_ipa_hybrid(test_text, language)
        
        review_results[language] = {
            "text": test_text,
            "ipa": ipa,
            "quality_rating": None,  # To be filled by linguist
            "accuracy_notes": None,  # To be filled by linguist
            "used_tier": detect_used_tier(ipa, language)
        }
    
    # Save to JSON for manual review
    with open("ipa_quality_review.json", "w", encoding="utf-8") as f:
        json.dump(review_results, f, ensure_ascii=False, indent=2)
    
    return review_results

def get_sample_text_for_language(language: str) -> str:
    """Get appropriate sample text for each language."""
    samples = {
        "English": "The quick brown fox jumps over the lazy dog",
        "Spanish": "El rÃ¡pido zorro marrÃ³n salta sobre el perro perezoso",
        "French": "Le rapide renard brun saute par-dessus le chien paresseux",
        "German": "Der schnelle braune Fuchs springt Ã¼ber den faulen Hund",
        "Chinese (Simplified)": "æ•æ·çš„æ£•è‰²ç‹ç‹¸è·³è¿‡äº†æ‡’ç‹—",
        "Japanese": "ç´ æ—©ã„èŒ¶è‰²ã®ç‹ãŒæ€ ã‘ãŸçŠ¬ã‚’é£›ã³è¶ŠãˆãŸ",
        "Korean": "ë¹ ë¥¸ ê°ˆìƒ‰ ì—¬ìš°ê°€ ê²Œìœ¼ë¥¸ ê°œë¥¼ ë›°ì–´ ë„˜ì—ˆë‹¤",
        "Hindi": "à¤¤à¥‡à¤œ à¤­à¥‚à¤°à¥€ à¤²à¥‹à¤®à¤¡à¤¼à¥€ à¤†à¤²à¤¸à¥€ à¤•à¥à¤¤à¥à¤¤à¥‡ à¤•à¥‡ à¤Šà¤ªà¤° à¤•à¥‚à¤¦à¤¤à¥€ à¤¹à¥ˆ",
        "Arabic": "Ø§Ù„Ø«Ø¹Ù„Ø¨ Ø§Ù„Ø¨Ù†ÙŠ Ø§Ù„Ø³Ø±ÙŠØ¹ ÙŠÙ‚ÙØ² ÙÙˆÙ‚ Ø§Ù„ÙƒÙ„Ø¨ Ø§Ù„ÙƒØ³ÙˆÙ„",
        "Russian": "Ğ‘Ñ‹ÑÑ‚Ñ€Ğ°Ñ ĞºĞ¾Ñ€Ğ¸Ñ‡Ğ½ĞµĞ²Ğ°Ñ Ğ»Ğ¸ÑĞ° Ğ¿Ñ€Ñ‹Ğ³Ğ°ĞµÑ‚ Ñ‡ĞµÑ€ĞµĞ· Ğ»ĞµĞ½Ğ¸Ğ²ÑƒÑ ÑĞ¾Ğ±Ğ°ĞºÑƒ",
        "Portuguese": "A raposa marrom rÃ¡pida pula sobre o cachorro preguiÃ§oso",
        "Italian": "La volpe marrone veloce salta sopra il cane pigro",
        "Dutch": "De snelle bruine vos springt over de luie hond",
        "Swedish": "Den snabba bruna rÃ¤ven hoppar Ã¶ver den lata hunden",
        "Greek": "Î— Î³ÏÎ®Î³Î¿ÏÎ· ÎºÎ±Ï†Î­ Î±Î»ÎµÏ€Î¿Ï Ï€Î·Î´Î¬ÎµÎ¹ Ï€Î¬Î½Ï‰ Î±Ï€ÏŒ Ï„Î¿ Ï„ÎµÎ¼Ï€Î­Î»Î¹ÎºÎ¿ ÏƒÎºÏ…Î»Î¯",
        "Hebrew": "×”×©×•×¢×œ ×”×—×•× ×”××”×™×¨ ×§×•×¤×¥ ××¢×œ ×”×›×œ×‘ ×”×¢×¦×œ×Ÿ",
        "Tamil": "à®µà®¿à®°à¯ˆà®µà®¾à®© à®ªà®´à¯à®ªà¯à®ªà¯ à®¨à®¿à®± à®¨à®°à®¿ à®šà¯‹à®®à¯à®ªà¯‡à®±à®¿ à®¨à®¾à®¯à¯à®•à¯à®•à¯ à®®à¯‡à®²à¯ à®•à¯à®¤à®¿à®•à¯à®•à®¿à®±à®¤à¯",
        "Thai": "à¸ªà¸¸à¸™à¸±à¸‚à¸ªà¸µà¸™à¹‰à¸³à¸•à¸²à¸¥à¸—à¸µà¹ˆà¹€à¸£à¹‡à¸§à¸à¸£à¸°à¹‚à¸”à¸”à¸‚à¹‰à¸²à¸¡à¸ªà¸¸à¸™à¸±à¸‚à¸‚à¸µà¹‰à¹€à¸à¸µà¸¢à¸ˆ",
        "Vietnamese": "Con cÃ¡o nÃ¢u nhanh nháº£y qua con chÃ³ lÆ°á»i biáº¿ng",
        "Swahili": "Mbwa ya kahawia ya haraka huruka juu ya mbwa mvivu"
    }
    return samples.get(language, "hello world")
```

#### **3.3 Performance Testing & Optimization**

##### **3.3.1 Load Testing**
```python
def performance_test_all_languages():
    """Test performance across all 77 languages."""
    ipa_service = IPAService()
    
    results = {
        "individual_times": {},
        "total_time": 0,
        "avg_time_per_language": 0,
        "max_time": 0,
        "min_time": float('inf')
    }
    
    start_total = time.time()
    
    for language, text, _ in COMPREHENSIVE_TEST_CASES:
        start = time.time()
        ipa = ipa_service.generate_ipa_hybrid(text, language)
        end = time.time()
        
        response_time = end - start
        results["individual_times"][language] = response_time
        results["max_time"] = max(results["max_time"], response_time)
        results["min_time"] = min(results["min_time"], response_time)
    
    results["total_time"] = time.time() - start_total
    results["avg_time_per_language"] = results["total_time"] / len(COMPREHENSIVE_TEST_CASES)
    
    # Performance assertions
    assert results["avg_time_per_language"] < 3.0, f"Average time too slow: {results['avg_time_per_language']}"
    assert results["max_time"] < 10.0, f"Max time too slow: {results['max_time']}"
    
    return results
```

##### **3.3.2 Caching Performance Test**
```python
def test_caching_performance():
    """Test performance improvement with caching."""
    ipa_service = IPAService()
    
    # Test repeated calls (should benefit from caching)
    test_cases = [("English", "hello world")] * 10
    
    start = time.time()
    for language, text in test_cases:
        ipa = ipa_service.generate_ipa_hybrid(text, language)
    end = time.time()
    
    avg_time = (end - start) / len(test_cases)
    
    # With caching, average should be < 0.5s
    assert avg_time < 0.5, f"Caching not effective: {avg_time}s average"
    
    return {"avg_cached_time": avg_time}
```

##### **3.3.3 Memory and Resource Testing**
```python
def test_memory_usage():
    """Test memory usage during bulk processing."""
    import psutil
    import os
    
    process = psutil.Process(os.getpid())
    initial_memory = process.memory_info().rss / 1024 / 1024  # MB
    
    ipa_service = IPAService()
    
    # Process all test cases
    for language, text, _ in COMPREHENSIVE_TEST_CASES:
        ipa = ipa_service.generate_ipa_hybrid(text, language)
    
    final_memory = process.memory_info().rss / 1024 / 1024  # MB
    memory_increase = final_memory - initial_memory
    
    # Memory increase should be reasonable (< 500MB)
    assert memory_increase < 500, f"Excessive memory usage: {memory_increase}MB"
    
    return {"initial_mb": initial_memory, "final_mb": final_memory, "increase_mb": memory_increase}
```

#### **3.4 Integration Testing**

##### **3.4.1 End-to-End Pipeline Testing**
```python
def test_full_pipeline_integration():
    """Test IPA service integration with sentence generation pipeline."""
    from sentence_generator import SentenceGenerator
    
    generator = SentenceGenerator()
    
    # Test languages that should work end-to-end
    test_languages = ["English", "Spanish", "Hindi", "Chinese (Simplified)", "Japanese"]
    
    for language in test_languages:
        try:
            # Generate sentence with IPA
            result = generator.generate_sentence(language, difficulty="beginner")
            
            # Verify IPA field is populated
            assert result.get("ipa"), f"Empty IPA in pipeline for {language}"
            assert result["ipa"] != "", f"Empty IPA string for {language}"
            
            # Verify no Pinyin contamination
            if language not in ["Chinese (Simplified)", "Chinese (Traditional)"]:
                assert not any(char in result["ipa"] for char in 'ÄÄ“Ä«ÅÅ«Ç–ÇÄ›ÇÇ’Ç”Çš'), f"Pinyin in {language} IPA"
            
            print(f"âœ… Pipeline integration successful for {language}")
            
        except Exception as e:
            print(f"âŒ Pipeline integration failed for {language}: {e}")
            raise
```

##### **3.4.2 Regression Testing**
```python
def test_regression_existing_functionality():
    """Ensure existing functionality still works."""
    ipa_service = IPAService()
    
    # Test existing supported languages
    existing_tests = [
        ("English", "hello", "hÉ™ËˆlÉ™ÊŠ"),
        ("Spanish", "hola", "Ëˆola"),
        ("Hindi", "à¤¨à¤®à¤¸à¥à¤¤à¥‡", "nÉ™mÉ™ste"),
        ("Arabic", "Ù…Ø±Ø­Ø¨Ø§", "marÄ§aban"),
        ("Chinese (Simplified)", "ä½ å¥½", "niË§Ë¥ xÉ‘ÊŠË§Ë©"),
    ]
    
    for language, text, expected_pattern in existing_tests:
        ipa = ipa_service.generate_ipa_hybrid(text, language)
        
        assert ipa, f"Regression: Empty IPA for {language}"
        assert not any(char in ipa for char in 'ÄÄ“Ä«ÅÅ«Ç–'), f"Regression: Pinyin in {language}"
        
        # Basic pattern matching for known cases
        if language == "English" and "h" in ipa.lower():
            assert "Ëˆ" in ipa or "ËŒ" in ipa, f"Regression: Missing stress marks in English IPA"
```

#### **3.5 Error Handling & Robustness Testing**

##### **3.5.1 Library Failure Simulation**
```python
def test_library_failure_robustness():
    """Test behavior when external libraries fail."""
    ipa_service = IPAService()
    
    # Simulate Epitran failure
    original_try_epitran = ipa_service._try_epitran
    ipa_service._try_epitran = lambda *args: ""  # Always fail
    
    try:
        ipa = ipa_service.generate_ipa_hybrid("hello", "English", "ai_fallback")
        assert ipa, "Should fallback when Epitran fails"
        assert ipa == "ai_fallback", "Should use AI fallback when Epitran fails"
    finally:
        ipa_service._try_epitran = original_try_epitran
    
    # Simulate Phonemizer failure
    original_try_phonemizer = ipa_service._try_phonemizer
    ipa_service._try_phonemizer = lambda *args: ""  # Always fail
    
    try:
        ipa = ipa_service.generate_ipa_hybrid("hello", "English", "ai_fallback")
        assert ipa, "Should fallback when Phonemizer fails"
        assert ipa == "ai_fallback", "Should use AI fallback when Phonemizer fails"
    finally:
        ipa_service._try_phonemizer = original_try_phonemizer
    
    # Simulate all failures
    ipa_service._try_epitran = lambda *args: ""
    ipa_service._try_phonemizer = lambda *args: ""
    
    try:
        ipa = ipa_service.generate_ipa_hybrid("hello", "English", "")
        assert ipa, "Should provide placeholder when all tiers fail"
        assert ipa == "[IPA unavailable for English]", "Should use placeholder"
    finally:
        ipa_service._try_epitran = original_try_epitran
        ipa_service._try_phonemizer = original_try_phonemizer
```

##### **3.5.2 Timeout and Performance Boundary Testing**
```python
def test_timeout_boundaries():
    """Test timeout handling and performance boundaries."""
    import signal
    
    def timeout_handler(signum, frame):
        raise TimeoutError("Test timeout")
    
    ipa_service = IPAService()
    
    # Test with very long text that might cause timeouts
    long_text = "word " * 1000  # 5000 characters
    
    # Set 5-second timeout
    signal.signal(signal.SIGALRM, timeout_handler)
    signal.alarm(5)
    
    try:
        ipa = ipa_service.generate_ipa_hybrid(long_text, "English")
        assert ipa, "Should handle long text gracefully"
        signal.alarm(0)  # Cancel timeout
    except TimeoutError:
        pytest.fail("IPA generation timed out on long text")
    finally:
        signal.alarm(0)
```

### **Phase 3 Deliverables**
- âœ… **Comprehensive Test Suite**: 77-language coverage with edge cases
- âœ… **Quality Assessment Framework**: Automated metrics + manual review process  
- âœ… **Performance Benchmarks**: Load testing, caching validation, memory profiling
- âœ… **Integration Tests**: End-to-end pipeline validation + regression testing
- âœ… **Error Handling Tests**: Library failure simulation + timeout testing
- âœ… **Test Results Report**: Detailed coverage, quality, and performance metrics

### **Phase 4: Integration & Deployment (Week 4)**

#### **4.1 Integration Testing**
- **End-to-End**: Test with sentence generation pipeline
- **Regression Testing**: Ensure existing functionality unchanged
- **Cross-Language Consistency**: Verify similar languages produce consistent quality

#### **4.2 Deployment Strategy**
- **Staging First**: Deploy to test environment
- **Gradual Rollout**: Enable for 10 languages, monitor, expand
- **Monitoring**: Track success rates, quality metrics, error rates

#### **4.3 Documentation & Maintenance**
- **API Documentation**: Update IPAService docstrings
- **Troubleshooting Guide**: Common issues and solutions
- **Version Control**: Track mapping updates and improvements

## ğŸ“Š QUALITY METRICS & SUCCESS CRITERIA

### **Coverage Metrics**
- âœ… **100% Language Support**: All 77 languages covered
- âœ… **Zero Empty Returns**: Never return empty strings
- âœ… **Fallback Guarantee**: Always provide IPA or meaningful placeholder

### **Quality Metrics**
- ğŸ¯ **Accuracy**: 80%+ acceptable IPA quality across all languages
- ğŸ¯ **Validation**: <10% validation failures (but still return results)
- ğŸ¯ **Pinyin-Free**: Zero Pinyin contamination in IPA output

### **Performance Metrics**
- âš¡ **Latency**: <3s average response time
- âš¡ **Reliability**: >95% success rate across all languages
- âš¡ **Caching**: 50%+ cache hit rate for repeated requests

### **User Experience Metrics**
- ğŸ‘¤ **No Broken Cards**: IPA fields always populated in Anki decks
- ğŸ‘¤ **Consistent Quality**: Similar quality across language families
- ğŸ‘¤ **Fast Generation**: No noticeable delays in sentence creation

## ğŸ”§ DETAILED CODE REFERENCE

### **Complete IPAService Implementation**
```python
import logging
from typing import Dict, Optional

logger = logging.getLogger(__name__)

class IPAService:
    """
    Enhanced IPA Service supporting all 77 languages via tiered approach.
    
    Tiers:
    1. Epitran (highest quality, ~60 languages)
    2. Phonemizer + espeak-ng (broad coverage, 77 languages)
    3. AI fallback (universal, guaranteed non-empty)
    """
    
    def __init__(self):
        # Existing basic mappings
        self.language_map = {
            "Chinese (Simplified)": "cmn-Latn",
            "Chinese (Traditional)": "cmn-Latn",
            "English": "eng-Latn",
            "Spanish": "spa-Latn",
            "French": "fra-Latn",
            "German": "deu-Latn",
            "Italian": "ita-Latn",
            "Portuguese": "por-Latn",
            "Russian": "rus-Cyrl",
            "Japanese": "jpn-Hira",
            "Korean": "kor-Hang",
            "Hindi": "hin-Deva",
            "Arabic": "ara-Arab",
        }
        
        # Comprehensive mappings for all 77 languages
        self.epitran_map = self._load_epitran_mappings()
        self.phonemizer_map = self._load_phonemizer_mappings()
    
    def _load_epitran_mappings(self) -> Dict[str, Optional[str]]:
        """Load Epitran language codes for supported languages."""
        return {
            # Indo-European (23 languages)
            "English": "eng-Latn",
            "German": "deu-Latn",
            "Dutch": "nld-Latn",
            "Swedish": "swe-Latn",
            "Danish": "dan-Latn",
            "Norwegian": "nob-Latn",
            "Icelandic": "isl-Latn",
            "Spanish": "spa-Latn",
            "French": "fra-Latn",
            "Italian": "ita-Latn",
            "Portuguese": "por-Latn",
            "Romanian": "ron-Latn",
            "Catalan": "cat-Latn",
            "Russian": "rus-Cyrl",
            "Polish": "pol-Latn",
            "Czech": "ces-Latn",
            "Ukrainian": "ukr-Cyrl",
            "Bulgarian": "bul-Cyrl",
            "Serbian": "srp-Latn",  # Latin script
            "Hindi": "hin-Deva",
            "Bengali": "ben-Beng",
            "Persian": "fas-Arab",
            "Urdu": "urd-Arab",
            "Punjabi": "pan-Guru",
            "Gujarati": "guj-Deva",
            "Marathi": "mar-Deva",
            "Greek": "ell-Grek",
            "Lithuanian": "lit-Latn",
            "Latvian": "lav-Latn",
            "Irish": "gle-Latn",
            "Welsh": "cym-Latn",
            "Breton": "bre-Latn",
            "Armenian": "hye-Armn",
            "Albanian": "sqi-Latn",
            
            # Afro-Asiatic (12 languages)
            "Arabic": "ara-Arab",
            "Hebrew": "heb-Hebr",
            "Amharic": "amh-Ethi",
            "Hausa": "hau-Latn",
            "Somali": None,  # Not supported
            "Tigrinya": "tir-Ethi",
            "Berber": None,  # Not supported
            "Coptic": "cop-Copt",
            "Maltese": "mlt-Latn",
            
            # Niger-Congo (15 languages)
            "Swahili": "swa-Latn",
            "Zulu": "zul-Latn",
            "Yoruba": "yor-Latn",
            "Igbo": "ibo-Latn",
            "Hausa": "hau-Latn",  # Duplicate, use same
            "Wolof": "wol-Latn",
            "Bambara": None,  # Not supported
            "Ewe": "ewe-Latn",
            "Tswana": "tsn-Latn",
            "Sesotho": "sot-Latn",
            
            # Austronesian (7 languages)
            "Malay": "msa-Latn",
            "Indonesian": "ind-Latn",
            "Tagalog": "tgl-Latn",
            "Maori": "mri-Latn",
            "Hawaiian": "haw-Latn",
            "Malagasy": "mlg-Latn",
            "Javanese": None,  # Not supported
            
            # Turkic (6 languages)
            "Turkish": "tur-Latn",
            "Uzbek": "uzb-Latn",
            "Kazakh": "kaz-Cyrl",
            "Kyrgyz": "kir-Cyrl",
            "Tatar": "tat-Cyrl",
            "Azerbaijani": "aze-Latn",
            
            # Dravidian (4 languages)
            "Tamil": "tam-Taml",
            "Telugu": "tel-Telu",
            "Kannada": "kan-Knda",
            "Malayalam": "mal-Mlym",
            
            # Japonic (2 languages)
            "Japanese": "jpn-Hira",
            "Ryukyuan": None,  # Not supported
            
            # Koreanic (1 language)
            "Korean": "kor-Hang",
            
            # Tai-Kadai (3 languages)
            "Thai": "tha-Thai",
            "Lao": "lao-Laoo",
            "Zhuang": None,  # Not supported
            
            # Hmong-Mien (2 languages)
            "Hmong": None,  # Not supported
            "Mien": None,  # Not supported
            
            # Austroasiatic (4 languages)
            "Vietnamese": "vie-Latn",
            "Khmer": "khm-Khmr",
            "Mon": None,  # Not supported
            "Khasi": None,  # Not supported
            
            # Tibeto-Burman (6 languages) - overlaps with Sino-Tibetan
            "Tibetan": "bod-Tibt",
            "Burmese": "mya-Mymr",
            "Karen": None,  # Not supported
            "Yi": "iii-Yiii",
            "Bai": None,  # Not supported
            "Tujia": None,  # Not supported
            
            # Sino-Tibetan (8 languages) - Chinese handled specially
            "Chinese (Simplified)": None,  # Skip Epitran
            "Chinese (Traditional)": None,  # Skip Epitran
            "Tibetan": "bod-Tibt",  # Duplicate, use same
            "Burmese": "mya-Mymr",  # Duplicate, use same
            "Karen": None,  # Not supported
            "Yi": "iii-Yiii",  # Duplicate, use same
            "Bai": None,  # Not supported
            "Tujia": None,  # Not supported
            
            # Other isolates and small families
            "Nubian": None,  # Not supported
            "Basque": "eus-Latn",
            "Na-Dene": None,  # Not supported
            "Eskimo-Aleut": None,  # Not supported
            "Australian Aboriginal": None,  # Not supported
        }
    
    def _load_phonemizer_mappings(self) -> Dict[str, str]:
        """Load Phonemizer BCP 47 codes for all languages."""
        return {
            # Complete mappings for all 77 languages
            "English": "en",
            "German": "de",
            "Dutch": "nl",
            "Swedish": "sv",
            "Danish": "da",
            "Norwegian": "nb",  # BokmÃ¥l
            "Icelandic": "is",
            "Spanish": "es",
            "French": "fr",
            "Italian": "it",
            "Portuguese": "pt",
            "Romanian": "ro",
            "Catalan": "ca",
            "Russian": "ru",
            "Polish": "pl",
            "Czech": "cs",
            "Ukrainian": "uk",
            "Bulgarian": "bg",
            "Serbian": "sr",
            "Hindi": "hi",
            "Bengali": "bn",
            "Persian": "fa",
            "Urdu": "ur",
            "Punjabi": "pa",
            "Gujarati": "gu",
            "Marathi": "mr",
            "Greek": "el",
            "Lithuanian": "lt",
            "Latvian": "lv",
            "Irish": "ga",
            "Welsh": "cy",
            "Breton": "br",
            "Armenian": "hy",
            "Albanian": "sq",
            
            # Afro-Asiatic
            "Arabic": "ar",
            "Hebrew": "he",
            "Amharic": "am",
            "Hausa": "ha",
            "Somali": "so",
            "Tigrinya": "ti",
            "Berber": "ber",  # Generic
            "Coptic": "cop",
            "Maltese": "mt",
            
            # Niger-Congo
            "Swahili": "sw",
            "Zulu": "zu",
            "Yoruba": "yo",
            "Igbo": "ig",
            "Hausa": "ha",  # Duplicate
            "Wolof": "wo",
            "Bambara": "bm",
            "Ewe": "ee",
            "Tswana": "tn",
            "Sesotho": "st",
            
            # Austronesian
            "Malay": "ms",
            "Indonesian": "id",
            "Tagalog": "tl",
            "Maori": "mi",
            "Hawaiian": "haw",
            "Malagasy": "mg",
            "Javanese": "jv",
            
            # Turkic
            "Turkish": "tr",
            "Uzbek": "uz",
            "Kazakh": "kk",
            "Kyrgyz": "ky",
            "Tatar": "tt",
            "Azerbaijani": "az",
            
            # Dravidian
            "Tamil": "ta",
            "Telugu": "te",
            "Kannada": "kn",
            "Malayalam": "ml",
            
            # Japonic
            "Japanese": "ja",
            "Ryukyuan": "ja",  # Fallback to Japanese
            
            # Koreanic
            "Korean": "ko",
            
            # Tai-Kadai
            "Thai": "th",
            "Lao": "lo",
            "Zhuang": "za",
            
            # Hmong-Mien
            "Hmong": "hmn",
            "Mien": "hmn",  # Fallback
            
            # Austroasiatic
            "Vietnamese": "vi",
            "Khmer": "km",
            "Mon": "mnw",
            "Khasi": "kha",
            
            # Tibeto-Burman
            "Tibetan": "bo",
            "Burmese": "my",
            "Karen": "kar",  # Generic
            "Yi": "ii",
            "Bai": "ba",
            "Tujia": "de",  # Fallback
            
            # Sino-Tibetan
            "Chinese (Simplified)": "cmn",  # Mandarin
            "Chinese (Traditional)": "cmn",  # Mandarin
            "Tibetan": "bo",  # Duplicate
            "Burmese": "my",  # Duplicate
            "Karen": "kar",  # Duplicate
            "Yi": "ii",  # Duplicate
            "Bai": "ba",  # Duplicate
            "Tujia": "de",  # Duplicate
            
            # Other
            "Nubian": "fia",  # Generic Nubian
            "Basque": "eu",
            "Navajo": "nv",
            "Apache": "nv",  # Fallback
            "Inuit": "iu",
            "Aleut": "ale",
            "Pitjantjatjara": "pit",
            "Warlpiri": "wbp",
            "Arrernte": "aer",
        }
    
    def generate_ipa_hybrid(self, text: str, language: str, ai_ipa: str = "") -> str:
        """
        Generate IPA using tiered approach with guaranteed non-empty return.
        
        Tiers:
        1. Epitran (highest quality when available)
        2. Phonemizer + espeak-ng (broad coverage)
        3. AI fallback (universal guarantee)
        
        Args:
            text: Text to transliterate
            language: Language name
            ai_ipa: AI-generated IPA fallback
            
        Returns:
            IPA string (never empty)
        """
        if not text or not text.strip():
            return ""
        
        # Tier 1: Epitran (highest quality)
        ipa = self._try_epitran(text, language)
        if ipa and self._validate_ipa(ipa, language):
            logger.info(f"IPA success via Epitran for {language}")
            return ipa
        
        # Tier 2: Phonemizer (broad coverage)
        ipa = self._try_phonemizer(text, language)
        if ipa and self._validate_ipa(ipa, language):
            logger.info(f"IPA success via Phonemizer for {language}")
            return ipa
        
        # Tier 3: AI fallback (guaranteed)
        fallback_ipa = self._ensure_fallback_ipa(ai_ipa, text, language)
        logger.info(f"IPA fallback used for {language}")
        return fallback_ipa
    
    def _try_epitran(self, text: str, language: str) -> str:
        """Attempt Epitran transliteration."""
        # Skip Chinese (returns Pinyin-like output)
        if "Chinese" in language:
            return ""
        
        epi_code = self.epitran_map.get(language)
        if not epi_code:
            return ""
        
        try:
            import epitran
            epi = epitran.Epitran(epi_code)
            ipa = epi.transliterate(text)
            
            # Basic quality validation
            if ipa and ipa != text and len(ipa.strip()) > 0:
                return ipa.strip()
            return ""
            
        except Exception as e:
            logger.warning(f"Epitran failed for {language}: {e}")
            return ""
    
    def _try_phonemizer(self, text: str, language: str) -> str:
        """Attempt Phonemizer with espeak-ng backend."""
        phone_code = self.phonemizer_map.get(language)
        if not phone_code:
            return ""
        
        try:
            import phonemizer
            
            ipa = phonemizer.phonemize(
                text,
                language=phone_code,
                backend='espeak',
                strip=True,
                preserve_punctuation=False,
                with_stress=True
            )
            
            # Clean and validate
            ipa = ipa.strip()
            if ipa and len(ipa) > 0:
                return ipa
            return ""
            
        except Exception as e:
            logger.warning(f"Phonemizer failed for {language}: {e}")
            return ""
    
    def _validate_ipa(self, ipa: str, language: str) -> bool:
        """Validate IPA but allow best-effort returns."""
        if not ipa or not ipa.strip():
            return False
        
        # Use comprehensive validation
        from generation_utils import validate_ipa_output
        is_valid, validation_msg = validate_ipa_output(ipa, language)
        
        if is_valid:
            return True
        
        # Log warning but don't reject - accept best effort
        logger.warning(f"IPA validation failed for {language}: {validation_msg}")
        
        # Basic quality checks
        ipa_clean = ipa.strip()
        
        # Reject obvious Pinyin (Chinese-specific check)
        if any(char in ipa_clean for char in 'ÄÄ“Ä«ÅÅ«Ç–ÇÄ›ÇÇ’Ç”Çš'):
            logger.warning(f"Rejected Pinyin contamination in {language} IPA")
            return False
        
        # Accept if it has content and looks IPA-like
        return len(ipa_clean) > 0
    
    def _ensure_fallback_ipa(self, ai_ipa: str, text: str, language: str) -> str:
        """Guarantee non-empty IPA return."""
        # Try AI IPA first
        if ai_ipa and ai_ipa.strip():
            if self._validate_ipa(ai_ipa, language):
                return ai_ipa
            # Accept even if validation fails (best effort)
            if len(ai_ipa.strip()) > 0:
                return ai_ipa
        
        # Ultimate fallback: meaningful placeholder
        logger.warning(f"All IPA tiers failed for {language}, using placeholder")
        return f"[IPA unavailable for {language}]"
```

## ğŸ§ª TESTING & VALIDATION REFERENCE

### **Comprehensive Test Suite**
```python
import pytest
from services.sentence_generation.ipa_service import IPAService

class TestIPAService:
    def setup_method(self):
        self.ipa_service = IPAService()
    
    def test_all_77_languages_coverage(self):
        """Test that all 77 languages return non-empty IPA."""
        test_text = "hello"
        
        languages = [
            "English", "Spanish", "Hindi", "Arabic", "Chinese (Simplified)",
            # ... all 77 languages
        ]
        
        for language in languages:
            ipa = self.ipa_service.generate_ipa_hybrid(test_text, language)
            assert ipa, f"Empty IPA for {language}"
            assert not any(char in ipa for char in 'ÄÄ“Ä«ÅÅ«Ç–ÇÄ›ÇÇ’Ç”Çš'), f"Pinyin in {language}"
    
    def test_tier_fallback(self):
        """Test that tiers fall back correctly."""
        # Test with unsupported language
        ipa = self.ipa_service.generate_ipa_hybrid("test", "Unsupported Language", "fallback_ipa")
        assert ipa == "fallback_ipa"  # Should use AI fallback
    
    def test_chinese_special_handling(self):
        """Test Chinese skips Epitran."""
        # Mock to ensure Epitran not called for Chinese
        ipa = self.ipa_service.generate_ipa_hybrid("ä½ å¥½", "Chinese (Simplified)")
        # Should use Phonemizer or fallback, not Epitran
        assert ipa
        assert not any(char in ipa for char in 'ÄÄ“Ä«ÅÅ«Ç–'), "Chinese should not return Pinyin"
    
    def test_validation_best_effort(self):
        """Test validation allows best-effort returns."""
        # Even if validation fails, should return result
        ai_ipa = "invalid_but_present"
        ipa = self.ipa_service.generate_ipa_hybrid("test", "English", ai_ipa)
        assert ipa  # Should not be empty
```

### **Quality Assessment Framework**
```python
def assess_ipa_quality(ipa_results: Dict[str, str]) -> Dict[str, float]:
    """Assess IPA quality across languages."""
    metrics = {
        "coverage": 0.0,  # % of languages with IPA
        "non_empty": 0.0,  # % of non-empty results
        "validation_pass": 0.0,  # % passing validation
        "pinyin_free": 0.0,  # % without Pinyin contamination
        "avg_length_ratio": 0.0,  # Text length to IPA length ratio
    }
    
    # Calculate metrics...
    return metrics
```

## ğŸ“ˆ TIMELINE & MILESTONES

### **Week 1: Research & Architecture**
- âœ… Complete language mappings research
- âœ… Dependency analysis and setup
- âœ… Architecture design and validation
- **Deliverable**: Complete implementation plan

### **Week 2: Core Implementation**
- âœ… Expand IPAService with comprehensive mappings
- âœ… Implement Epitran tier with Chinese special handling
- âœ… Implement Phonemizer tier with espeak-ng
- âœ… Implement validation and fallback logic
- **Deliverable**: Functional IPAService extension

### **Week 3: Testing & Quality Assurance**
- âœ… Unit tests for all 77 languages
- âœ… Quality assessment and manual review
- âœ… Performance testing and optimization
- âœ… Integration testing with sentence generation
- **Deliverable**: Production-ready code with test coverage

### **Week 4: Deployment & Monitoring**
- âœ… Staging deployment and validation
- âœ… Gradual production rollout
- âœ… Monitoring setup and alerting
- âœ… Documentation and maintenance guides
- **Deliverable**: Live system with monitoring

### **Success Metrics Timeline**
- **End of Week 2**: 100% coverage, guaranteed non-empty returns
- **End of Week 3**: >80% quality accuracy, <5% failure rate
- **End of Week 4**: Full production deployment, monitoring active

## ğŸ¯ NEXT STEPS AFTER IPA EXTENSION

1. **Validate Integration**: Test with full sentence generation pipeline
2. **Monitor Quality**: Track real-world IPA accuracy and user feedback
3. **Expand Coverage**: Add new languages as they become available in libraries
4. **Performance Optimization**: Implement caching and async processing
5. **User Feedback Loop**: Incorporate learner feedback on IPA quality

---

**EXECUTION**: Begin with Phase 1 research. Use this prompt to guide the complete IPA extension implementation across all 77 languages.</content>
<parameter name="filePath">d:\Language Learning\LanguagLearning\ipa_master_prompt.md